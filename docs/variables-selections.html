<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Variables Selections | The Association Between Travel Behavior and Urban Form</title>
  <meta name="description" content="This is a field paper using the bookdown package. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.24.1 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Variables Selections | The Association Between Travel Behavior and Urban Form" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a field paper using the bookdown package. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="qushen26/field_paper" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Variables Selections | The Association Between Travel Behavior and Urban Form" />
  
  <meta name="twitter:description" content="This is a field paper using the bookdown package. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Shen Qu" />


<meta name="date" content="2021-10-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multicollinearity.html"/>
<link rel="next" href="new-trends.html"/>
<script src="book_assets/header-attrs-2.11/header-attrs.js"></script>
<script src="book_assets/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="book_assets/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="book_assets/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="book_assets/kePrint-0.0.1/kePrint.js"></script>
<link href="book_assets/lightable-0.0.1/lightable.css" rel="stylesheet" />



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Field Paper</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>Part I Theories and Framework</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#background"><i class="fa fa-check"></i><b>1.1</b> Background</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#analytical-framework"><i class="fa fa-check"></i><b>1.2</b> Analytical Framework</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#content-organization"><i class="fa fa-check"></i><b>1.3</b> Content Organization</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="form.html"><a href="form.html"><i class="fa fa-check"></i><b>2</b> Urban Form as Predictors</a>
<ul>
<li class="chapter" data-level="2.1" data-path="form.html"><a href="form.html#influencing-direction"><i class="fa fa-check"></i><b>2.1</b> Influencing Direction</a></li>
<li class="chapter" data-level="2.2" data-path="form.html"><a href="form.html#influencing-factors"><i class="fa fa-check"></i><b>2.2</b> Influencing Factors</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="form.html"><a href="form.html#individual-factors"><i class="fa fa-check"></i><b>2.2.1</b> Individual Factors</a></li>
<li class="chapter" data-level="2.2.2" data-path="form.html"><a href="form.html#environmental-factors"><i class="fa fa-check"></i><b>2.2.2</b> Environmental Factors</a></li>
<li class="chapter" data-level="2.2.3" data-path="form.html"><a href="form.html#density"><i class="fa fa-check"></i><b>2.2.3</b> Density</a></li>
<li class="chapter" data-level="2.2.4" data-path="form.html"><a href="form.html#d-variables"><i class="fa fa-check"></i><b>2.2.4</b> D-variables</a></li>
<li class="chapter" data-level="2.2.5" data-path="form.html"><a href="form.html#synthesized-index"><i class="fa fa-check"></i><b>2.2.5</b> Synthesized Index</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="form.html"><a href="form.html#meta-aanalysis"><i class="fa fa-check"></i><b>2.3</b> Meta-Aanalysis</a></li>
<li class="chapter" data-level="2.4" data-path="form.html"><a href="form.html#scale"><i class="fa fa-check"></i><b>2.4</b> Spatial Scales</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="form.html"><a href="form.html#modifiable-areal-unit-problem-maup"><i class="fa fa-check"></i><b>2.4.1</b> Modifiable areal unit problem (MAUP)</a></li>
<li class="chapter" data-level="2.4.2" data-path="form.html"><a href="form.html#aggregated-analysis"><i class="fa fa-check"></i><b>2.4.2</b> Aggregated Analysis</a></li>
<li class="chapter" data-level="2.4.3" data-path="form.html"><a href="form.html#disaggregated-analysis"><i class="fa fa-check"></i><b>2.4.3</b> Disaggregated Analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="travel.html"><a href="travel.html"><i class="fa fa-check"></i><b>3</b> Travel as Response</a>
<ul>
<li class="chapter" data-level="3.1" data-path="travel.html"><a href="travel.html#travel-variables"><i class="fa fa-check"></i><b>3.1</b> Travel Variables</a></li>
<li class="chapter" data-level="3.2" data-path="travel.html"><a href="travel.html#traveler-choice"><i class="fa fa-check"></i><b>3.2</b> Traveler Choice</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="travel.html"><a href="travel.html#rational-choice-theory"><i class="fa fa-check"></i><b>3.2.1</b> Rational Choice Theory</a></li>
<li class="chapter" data-level="3.2.2" data-path="travel.html"><a href="travel.html#bounded-rational-behavior"><i class="fa fa-check"></i><b>3.2.2</b> Bounded Rational Behavior</a></li>
<li class="chapter" data-level="3.2.3" data-path="travel.html"><a href="travel.html#theory-of-planned-behavior"><i class="fa fa-check"></i><b>3.2.3</b> Theory of Planned Behavior</a></li>
<li class="chapter" data-level="3.2.4" data-path="travel.html"><a href="travel.html#prospect-theory"><i class="fa fa-check"></i><b>3.2.4</b> Prospect Theory</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="travel.html"><a href="travel.html#human-mobility"><i class="fa fa-check"></i><b>3.3</b> Human Mobility</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="travel.html"><a href="travel.html#distance-based-theories"><i class="fa fa-check"></i><b>3.3.1</b> Distance Based Theories</a></li>
<li class="chapter" data-level="3.3.2" data-path="travel.html"><a href="travel.html#opportunity-based-theories"><i class="fa fa-check"></i><b>3.3.2</b> Opportunity Based Theories</a></li>
<li class="chapter" data-level="3.3.3" data-path="travel.html"><a href="travel.html#time-geography"><i class="fa fa-check"></i><b>3.3.3</b> Time Geography</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="travel.html"><a href="travel.html#probability-distributions"><i class="fa fa-check"></i><b>3.4</b> Probability Distributions</a></li>
<li class="chapter" data-level="3.5" data-path="travel.html"><a href="travel.html#summary-opt."><i class="fa fa-check"></i><b>3.5</b> Summary (Opt.)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="struc.html"><a href="struc.html"><i class="fa fa-check"></i><b>4</b> Model Structures</a>
<ul>
<li class="chapter" data-level="4.1" data-path="struc.html"><a href="struc.html#multistage"><i class="fa fa-check"></i><b>4.1</b> Multistage</a></li>
<li class="chapter" data-level="4.2" data-path="struc.html"><a href="struc.html#decision-tree"><i class="fa fa-check"></i><b>4.2</b> Decision Tree</a></li>
<li class="chapter" data-level="4.3" data-path="struc.html"><a href="struc.html#multi-scales"><i class="fa fa-check"></i><b>4.3</b> Multi-scales</a></li>
<li class="chapter" data-level="4.4" data-path="struc.html"><a href="struc.html#other-structures"><i class="fa fa-check"></i><b>4.4</b> Other Structures</a></li>
</ul></li>
<li class="part"><span><b>Part II Statistical Methods</b></span></li>
<li class="chapter" data-level="5" data-path="common-methods.html"><a href="common-methods.html"><i class="fa fa-check"></i><b>5</b> Common Methods</a>
<ul>
<li class="chapter" data-level="5.1" data-path="common-methods.html"><a href="common-methods.html#for-trip-distance"><i class="fa fa-check"></i><b>5.1</b> For Trip Distance</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="common-methods.html"><a href="common-methods.html#transformations"><i class="fa fa-check"></i><b>5.1.1</b> Transformations</a></li>
<li class="chapter" data-level="5.1.2" data-path="common-methods.html"><a href="common-methods.html#estimations"><i class="fa fa-check"></i><b>5.1.2</b> Estimations</a></li>
<li class="chapter" data-level="5.1.3" data-path="common-methods.html"><a href="common-methods.html#inference"><i class="fa fa-check"></i><b>5.1.3</b> Inference</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="common-methods.html"><a href="common-methods.html#for-mode-choice"><i class="fa fa-check"></i><b>5.2</b> For Mode Choice</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="common-methods.html"><a href="common-methods.html#logit-models"><i class="fa fa-check"></i><b>5.2.1</b> Logit Models</a></li>
<li class="chapter" data-level="5.2.2" data-path="common-methods.html"><a href="common-methods.html#multinomial-logit-models"><i class="fa fa-check"></i><b>5.2.2</b> Multinomial Logit models</a></li>
<li class="chapter" data-level="5.2.3" data-path="common-methods.html"><a href="common-methods.html#discret-choice-models"><i class="fa fa-check"></i><b>5.2.3</b> Discret Choice Models</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="common-methods.html"><a href="common-methods.html#for-tirp-generation"><i class="fa fa-check"></i><b>5.3</b> For Tirp Generation</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="common-methods.html"><a href="common-methods.html#negative-binomial-model"><i class="fa fa-check"></i><b>5.3.1</b> Negative Binomial Model</a></li>
<li class="chapter" data-level="5.3.2" data-path="common-methods.html"><a href="common-methods.html#quasi-poisson-model"><i class="fa fa-check"></i><b>5.3.2</b> Quasi-Poisson Model</a></li>
<li class="chapter" data-level="5.3.3" data-path="common-methods.html"><a href="common-methods.html#zero-inflated-and-hurdle-models"><i class="fa fa-check"></i><b>5.3.3</b> Zero-inflated and Hurdle Models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="several-issues.html"><a href="several-issues.html"><i class="fa fa-check"></i><b>6</b> Several Issues</a>
<ul>
<li class="chapter" data-level="6.1" data-path="several-issues.html"><a href="several-issues.html#assumptions"><i class="fa fa-check"></i><b>6.1</b> Assumptions</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="several-issues.html"><a href="several-issues.html#additive-and-linearity"><i class="fa fa-check"></i><b>6.1.1</b> Additive and linearity</a></li>
<li class="chapter" data-level="6.1.2" data-path="several-issues.html"><a href="several-issues.html#independent-identically-distributed-iid"><i class="fa fa-check"></i><b>6.1.2</b> Independent Identically Distributed (IID)</a></li>
<li class="chapter" data-level="6.1.3" data-path="several-issues.html"><a href="several-issues.html#normality"><i class="fa fa-check"></i><b>6.1.3</b> Normality</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="several-issues.html"><a href="several-issues.html#estimations-1"><i class="fa fa-check"></i><b>6.2</b> Estimations</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="several-issues.html"><a href="several-issues.html#least-squares-1"><i class="fa fa-check"></i><b>6.2.1</b> Least Squares</a></li>
<li class="chapter" data-level="6.2.2" data-path="several-issues.html"><a href="several-issues.html#standardized-coefficients-1"><i class="fa fa-check"></i><b>6.2.2</b> Standardized coefficients</a></li>
<li class="chapter" data-level="6.2.3" data-path="several-issues.html"><a href="several-issues.html#elasticity-1"><i class="fa fa-check"></i><b>6.2.3</b> Elasticity</a></li>
<li class="chapter" data-level="6.2.4" data-path="several-issues.html"><a href="several-issues.html#combined-effects"><i class="fa fa-check"></i><b>6.2.4</b> Combined effects?</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="several-issues.html"><a href="several-issues.html#inference-1"><i class="fa fa-check"></i><b>6.3</b> Inference</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="several-issues.html"><a href="several-issues.html#analysis-of-variance-1"><i class="fa fa-check"></i><b>6.3.1</b> Analysis of Variance</a></li>
<li class="chapter" data-level="6.3.2" data-path="several-issues.html"><a href="several-issues.html#hypothesis-test-1"><i class="fa fa-check"></i><b>6.3.2</b> Hypothesis Test</a></li>
<li class="chapter" data-level="6.3.3" data-path="several-issues.html"><a href="several-issues.html#confidence-intervals-1"><i class="fa fa-check"></i><b>6.3.3</b> Confidence Intervals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="adequacy.html"><a href="adequacy.html"><i class="fa fa-check"></i><b>7</b> Adequacy</a>
<ul>
<li class="chapter" data-level="7.1" data-path="adequacy.html"><a href="adequacy.html#goodness-of-fit"><i class="fa fa-check"></i><b>7.1</b> Goodness of fit</a></li>
<li class="chapter" data-level="7.2" data-path="adequacy.html"><a href="adequacy.html#residuals-analysis"><i class="fa fa-check"></i><b>7.2</b> Residuals Analysis</a></li>
<li class="chapter" data-level="7.3" data-path="adequacy.html"><a href="adequacy.html#heteroscedasticity"><i class="fa fa-check"></i><b>7.3</b> Heteroscedasticity</a></li>
<li class="chapter" data-level="7.4" data-path="adequacy.html"><a href="adequacy.html#autocorrelation"><i class="fa fa-check"></i><b>7.4</b> Autocorrelation</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="multicollinearity.html"><a href="multicollinearity.html"><i class="fa fa-check"></i><b>8</b> Multicollinearity</a>
<ul>
<li class="chapter" data-level="8.1" data-path="multicollinearity.html"><a href="multicollinearity.html#variance-inflation"><i class="fa fa-check"></i><b>8.1</b> Variance Inflation</a></li>
<li class="chapter" data-level="8.2" data-path="multicollinearity.html"><a href="multicollinearity.html#ridge-regression"><i class="fa fa-check"></i><b>8.2</b> Ridge Regression</a></li>
<li class="chapter" data-level="8.3" data-path="multicollinearity.html"><a href="multicollinearity.html#lasso-regression"><i class="fa fa-check"></i><b>8.3</b> Lasso Regression</a></li>
<li class="chapter" data-level="8.4" data-path="multicollinearity.html"><a href="multicollinearity.html#principal-components-regression"><i class="fa fa-check"></i><b>8.4</b> Principal Components Regression</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="variables-selections.html"><a href="variables-selections.html"><i class="fa fa-check"></i><b>9</b> Variables Selections</a>
<ul>
<li class="chapter" data-level="9.1" data-path="variables-selections.html"><a href="variables-selections.html#model-evaluation-criteria"><i class="fa fa-check"></i><b>9.1</b> Model Evaluation Criteria</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="variables-selections.html"><a href="variables-selections.html#mallows-c_p"><i class="fa fa-check"></i><b>9.1.1</b> Mallows <span class="math inline">\(C_p\)</span></a></li>
<li class="chapter" data-level="9.1.2" data-path="variables-selections.html"><a href="variables-selections.html#akaikebayesian-information-criterion-aicbic"><i class="fa fa-check"></i><b>9.1.2</b> Akaike/Bayesian Information Criterion (AIC/BIC)</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="variables-selections.html"><a href="variables-selections.html#selecting-procedure"><i class="fa fa-check"></i><b>9.2</b> Selecting Procedure</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="variables-selections.html"><a href="variables-selections.html#all-possible-regressions"><i class="fa fa-check"></i><b>9.2.1</b> All Possible Regressions</a></li>
<li class="chapter" data-level="9.2.2" data-path="variables-selections.html"><a href="variables-selections.html#best-subset-selection"><i class="fa fa-check"></i><b>9.2.2</b> Best Subset selection</a></li>
<li class="chapter" data-level="9.2.3" data-path="variables-selections.html"><a href="variables-selections.html#stepwise-regression"><i class="fa fa-check"></i><b>9.2.3</b> Stepwise Regression</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="variables-selections.html"><a href="variables-selections.html#underfitting-and-overfitting"><i class="fa fa-check"></i><b>9.3</b> Underfitting and Overfitting</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="variables-selections.html"><a href="variables-selections.html#underfitting"><i class="fa fa-check"></i><b>9.3.1</b> Underfitting</a></li>
<li class="chapter" data-level="9.3.2" data-path="variables-selections.html"><a href="variables-selections.html#overfitting"><i class="fa fa-check"></i><b>9.3.2</b> Overfitting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="new-trends.html"><a href="new-trends.html"><i class="fa fa-check"></i><b>10</b> New Trends</a>
<ul>
<li class="chapter" data-level="10.1" data-path="new-trends.html"><a href="new-trends.html#mixed-models-for-spatial-effects"><i class="fa fa-check"></i><b>10.1</b> Mixed Models for Spatial Effects</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="new-trends.html"><a href="new-trends.html#fixed-and-random-effects"><i class="fa fa-check"></i><b>10.1.1</b> Fixed and Random Effects</a></li>
<li class="chapter" data-level="10.1.2" data-path="new-trends.html"><a href="new-trends.html#crossed-and-nested-effects"><i class="fa fa-check"></i><b>10.1.2</b> Crossed and Nested Effects</a></li>
<li class="chapter" data-level="10.1.3" data-path="new-trends.html"><a href="new-trends.html#unbalanced-subgroup"><i class="fa fa-check"></i><b>10.1.3</b> Unbalanced Subgroup</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="new-trends.html"><a href="new-trends.html#non-linear-relationship"><i class="fa fa-check"></i><b>10.2</b> Non-Linear Relationship</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="new-trends.html"><a href="new-trends.html#polynomial-regression"><i class="fa fa-check"></i><b>10.2.1</b> Polynomial Regression</a></li>
<li class="chapter" data-level="10.2.2" data-path="new-trends.html"><a href="new-trends.html#basis-functions"><i class="fa fa-check"></i><b>10.2.2</b> Basis Functions</a></li>
<li class="chapter" data-level="10.2.3" data-path="new-trends.html"><a href="new-trends.html#non-parameter-regression"><i class="fa fa-check"></i><b>10.2.3</b> Non-parameter Regression</a></li>
<li class="chapter" data-level="10.2.4" data-path="new-trends.html"><a href="new-trends.html#generalized-additive-models"><i class="fa fa-check"></i><b>10.2.4</b> Generalized Additive Models</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="new-trends.html"><a href="new-trends.html#other-topic"><i class="fa fa-check"></i><b>10.3</b> Other Topic</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="meta-analysis.html"><a href="meta-analysis.html"><i class="fa fa-check"></i><b>11</b> Meta-Analysis</a>
<ul>
<li class="chapter" data-level="11.1" data-path="meta-analysis.html"><a href="meta-analysis.html#introduction"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="meta-analysis.html"><a href="meta-analysis.html#effect-sizes"><i class="fa fa-check"></i><b>11.2</b> Effect Sizes</a></li>
<li class="chapter" data-level="11.3" data-path="meta-analysis.html"><a href="meta-analysis.html#cross-study-heterogeneity"><i class="fa fa-check"></i><b>11.3</b> cross-study Heterogeneity</a></li>
<li class="chapter" data-level="11.4" data-path="meta-analysis.html"><a href="meta-analysis.html#meta-regression"><i class="fa fa-check"></i><b>11.4</b> Meta-Regression</a></li>
<li class="chapter" data-level="11.5" data-path="meta-analysis.html"><a href="meta-analysis.html#publication-bias"><i class="fa fa-check"></i><b>11.5</b> Publication Bias</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="meta-analysis.html"><a href="meta-analysis.html#checking-publication-bias"><i class="fa fa-check"></i><b>11.5.1</b> Checking Publication Bias</a></li>
<li class="chapter" data-level="11.5.2" data-path="meta-analysis.html"><a href="meta-analysis.html#standard-error-based-methods"><i class="fa fa-check"></i><b>11.5.2</b> Standard Error-based Methods</a></li>
<li class="chapter" data-level="11.5.3" data-path="meta-analysis.html"><a href="meta-analysis.html#p-value-based-methods"><i class="fa fa-check"></i><b>11.5.3</b> P value-based Methods</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Association Between Travel Behavior and Urban Form</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="variables-selections" class="section level1" number="9">
<h1><span class="header-section-number">Chapter 9</span> Variables Selections</h1>
<p>It has shown that lasso can help dropping off some variables.
To reduce variance, lasso allow the least squares estimates shrinking towards zero. This method is called shrinkage.
PCR is a dimension reduction method which projecting the original predictors into a lower-dimension space.
This chapter gives more approaches for systematic variable selections.</p>
<div id="model-evaluation-criteria" class="section level2" number="9.1">
<h2><span class="header-section-number">9.1</span> Model Evaluation Criteria</h2>
<p>Coefficient of determination <span class="math inline">\(R^2\)</span>is a basic measure of model performance. It has known that adding more predictor always increases <span class="math inline">\(R^2\)</span>. So the subset regression will stop to add new variables when the change of <span class="math inline">\(R^2\)</span> is not significant.</p>
<p>The improvement of <span class="math inline">\(R^2_{adj}\)</span> is that it is not a monotone increasing function. So one can select a maximum value on a convex curve.
Maximizing <span class="math inline">\(R^2_{adj}\)</span> is equivalent to minimizing residual mean square <span class="math inline">\(\mathrm{MSE}\)</span></p>
<p>When prediction of the mean response is the interest, <span class="math inline">\(R^2_{pred}\)</span> based on prediction mean square error (PRESS) statistic is more preferred. PRESS is useful for selecting from two competing models.</p>
<div id="mallows-c_p" class="section level3" number="9.1.1">
<h3><span class="header-section-number">9.1.1</span> Mallows <span class="math inline">\(C_p\)</span></h3>
<p>Beside above criteria, Mallows <span class="math inline">\(C_p\)</span> statistic is an important criteria related to the mean square error.
Suppose the fitted subset model has <span class="math inline">\(p\)</span> variables and expected response <span class="math inline">\(\hat y_i\)</span>. <span class="math inline">\(\mathrm{SSE}(p)\)</span> is the total sum square error including two variance components.
<span class="math inline">\(\mathrm{SSE}\)</span> is the true sum square error from the ‘true’ model, while the sum square bias is <span class="math inline">\(\mathrm{SSE}_B(p)=\sum_{i=1}^n(E[y_i]-E[\hat y_i])^2= \mathrm{SSE}(p) - \mathrm{SSE}\)</span>.
Then Mallows <span class="math inline">\(C_p\)</span> is</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
C_p=&amp;\frac{1}{\hat\sigma^2}( \mathrm{SSE}_B(p) + \sum_{i=1}^n\mathrm{Var}[\hat y_i] )\\
=&amp;\frac{1}{\hat\sigma^2}( \mathrm{SSE}(p) - \mathrm{SSE} + \sum_{i=1}^n\mathrm{Var}[\hat y_i] )\\
=&amp;\frac{1}{\hat\sigma^2}( \mathrm{SSE}(p) - (n-p)\hat\sigma^2 + p\hat\sigma^2 )\\
=&amp;\frac{\mathrm{SSE}(p)}{\hat\sigma^2} - n + 2p
\end{split}
\end{equation}\]</span></p>
<p>If the supposed model is true, <span class="math inline">\(\mathrm{SSE}_B(p)=0\)</span>, it gives <span class="math inline">\(E[C_p|\mathrm{Bias}=0] = \frac{(n-p)\sigma^2}{\sigma^2}-(n-2p)=p\)</span>
Hence, a plot of <span class="math inline">\(C_p\)</span> versus <span class="math inline">\(p\)</span> can help to find the best one from many points. The proper model should have <span class="math inline">\(C_p\approx p\)</span> and smaller <span class="math inline">\(C_p\)</span> is preferred.
<span class="math inline">\(C_p\)</span> is often increase when <span class="math inline">\(\mathrm{SSE}(p)\)</span> decrease by adding predictors. A personal judgment can choose the best tradeoff between samller <span class="math inline">\(C_p\)</span> and smaller <span class="math inline">\(\mathrm{SSE}(p)\)</span>.</p>
</div>
<div id="akaikebayesian-information-criterion-aicbic" class="section level3" number="9.1.2">
<h3><span class="header-section-number">9.1.2</span> Akaike/Bayesian Information Criterion (AIC/BIC)</h3>
<p>Akaike Information Criterion (AIC) is a penalized measure using maximum entropy.
AIC has a similar characteristic with <span class="math inline">\(C_p\)</span> that it will decrease when adding extra terms into the model. Then one can justify when the model can stop adding the new terms.</p>
<p><span class="math display" id="eq:aic">\[\begin{equation}
\mathrm{AIC}=n\ln\left(\frac1n \mathrm{SSE} \right)+ 2p
\tag{9.1}
\end{equation}\]</span></p>
<p>Bayesian information criterion (BIC) is the extension of AIC. <span class="citation"><a href="#ref-schwarzEstimatingDimensionModel1978" role="doc-biblioref">Schwarz</a> (<a href="#ref-schwarzEstimatingDimensionModel1978" role="doc-biblioref">1978</a>)</span> proposed a version of BIC with higher penalty for adding predictors when sample size is large.</p>
<p><span class="math display" id="eq:bic">\[\begin{equation}
\mathrm{BIC}=n\ln\left(\frac{1}{n} \mathrm{SSE} \right)+ p\ln(n)
\tag{9.2}
\end{equation}\]</span></p>
</div>
</div>
<div id="selecting-procedure" class="section level2" number="9.2">
<h2><span class="header-section-number">9.2</span> Selecting Procedure</h2>
<div id="all-possible-regressions" class="section level3" number="9.2.1">
<h3><span class="header-section-number">9.2.1</span> All Possible Regressions</h3>
<p>Suppose data has <span class="math inline">\(p\)</span> candidate predictors. There will be <span class="math inline">\(2^p\)</span> possible models.
For example, one can fit 1024 models using <span class="math inline">\(10\)</span> candidate predictors. Then one can select the best one based on aobve criteria.
For high-dimension data, fitting all possible regressions is very computing intensive.
In practice, people often choose other more efficient procedures.</p>
</div>
<div id="best-subset-selection" class="section level3" number="9.2.2">
<h3><span class="header-section-number">9.2.2</span> Best Subset selection</h3>
<p>Given a number of selected variables <span class="math inline">\(k\le p\)</span>, there could be <span class="math inline">\(p\choose k\)</span> possible combinations. By fitting all <span class="math inline">\(p\choose k\)</span> models with <span class="math inline">\(k\)</span> predictors, denote the best model with smallest <span class="math inline">\(SSE\)</span>, or largest <span class="math inline">\(R^2\)</span> as <span class="math inline">\(M_k\)</span>.
For each <span class="math inline">\(k=1,2,...,p\)</span>, there will be <span class="math inline">\(M_0,M_1,...,M_p\)</span> models. The final winner could be identified by comparing PRESS,</p>
</div>
<div id="stepwise-regression" class="section level3" number="9.2.3">
<h3><span class="header-section-number">9.2.3</span> Stepwise Regression</h3>
<ul>
<li>Forward Selection</li>
</ul>
<p>Forward selection starts from null model with only intercept. In each step of this procedure, a variable with greatest simple correlation with the response will be added into the model. If the new variable <span class="math inline">\(x_1\)</span> gets a large <span class="math inline">\(F\)</span> statistic and shows a significance effect on response, the second step will calculate the partial correlations between two sets of residuals. One is from the new fitted model <span class="math inline">\(\hat y=\beta_0+\beta_1x_1\)</span>. Another one is the model of other candidates on <span class="math inline">\(x_1\)</span>, that is <span class="math inline">\(\hat x_j=\alpha_{0j}+\alpha_{1j}x_1\)</span>, <span class="math inline">\(j=2,3,...,(p-1)\)</span>. Then the variable with largest partial correlation with <span class="math inline">\(y\)</span> is added into the model.
The two steps will repeat until the partial <span class="math inline">\(F\)</span> statistic is small at a given significant level.</p>
<ul>
<li>Backward Elimination</li>
</ul>
<p>Backward elimination starts from the full model with all candidates.
Given a preselected value of <span class="math inline">\(F_0\)</span>, each round will remove the variable with smallest <span class="math inline">\(F\)</span> and refit the model with rest predictors.
Then repeat to drop off one variable each round until all remaining predictors have a partial <span class="math inline">\(F_j&gt;F_0\)</span>.</p>
<ul>
<li>Stepwise Regression</li>
</ul>
<p>Stepwise regression combines forward selection and backward elimination together. During the forward steps, if some added predictors have a partial <span class="math inline">\(F_j&lt;F_0\)</span>, they also can be removed from the model by backward elimination.</p>
<p>It is common that some candidate predictors are correlated.
At the beginning, a predictor <span class="math inline">\(x_1\)</span> having greater simple correlation with response was added into the model.
However, along with a subset of related predictors were added, <span class="math inline">\(x_1\)</span> could become ‘useless’ in the model. In this case, backward elimination is necessary for achieving the best solution.</p>
</div>
</div>
<div id="underfitting-and-overfitting" class="section level2" number="9.3">
<h2><span class="header-section-number">9.3</span> Underfitting and Overfitting</h2>
<p>Suppose the true model is <span class="math inline">\(\mathbf{y}=\mathbf{X}\boldsymbol\beta +\boldsymbol\varepsilon=\mathbf{X}_1\boldsymbol\beta_1 + \mathbf{X}_2\boldsymbol\beta_2 + \boldsymbol\varepsilon\)</span>. <span class="math inline">\(\mathbf{X}\)</span> is full rank <span class="math inline">\(r(\mathbf{X})=r =r_1+r_2\)</span>, <span class="math inline">\(E[\boldsymbol\varepsilon]=0\)</span>, and <span class="math inline">\(Cov[\boldsymbol\varepsilon]= \sigma^2\mathbf{I}_n\)</span>.
The normal equation <span class="math inline">\(\mathbf{X&#39;X}\boldsymbol\beta=\mathbf{X&#39;y}\)</span> can be rewrite as</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
\mathbf{X}_1&#39;\mathbf{X}_1\boldsymbol\beta^0_1+\mathbf{X}_1&#39;\mathbf{X}_2\boldsymbol\beta^0_2&amp;=\mathbf{X}_1&#39;\mathbf{y}\\
\mathbf{X}_2&#39;\mathbf{X}_1\boldsymbol\beta^0_1+\mathbf{X}_2&#39;\mathbf{X}_2\boldsymbol\beta^0_2&amp;=\mathbf{X}_2&#39;\mathbf{y}\\
\end{split}
\end{equation}\]</span></p>
<p>Let <span class="math inline">\(\mathbf{P}_i=\mathbf{X}_i(\mathbf{X}_i&#39;\mathbf{X}_i)^{-}\mathbf{X}&#39;_i\)</span>, <span class="math inline">\(i=1,2\)</span>, and</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
\mathbf{M}_1=&amp;(\mathbf{X}&#39;_1\mathbf{X}_1)^{-}\mathbf{X}&#39;_1\mathbf{X}_2\\
\mathbf{M}_2=&amp;\mathbf{X}&#39;_2(\mathbf{I}-\mathbf{P}_1)\mathbf{X}_2
\end{split}
\end{equation}\]</span></p>
<p>Then,</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
\boldsymbol\beta^0_1=&amp;(\mathbf{X}&#39;_1\mathbf{X}_1)^{-}\mathbf{X}&#39;_1(\mathbf{y}-\mathbf{X}_2\boldsymbol\beta^0_2)\\
\boldsymbol\beta^0_2=&amp;[\mathbf{X}&#39;_2(\mathbf{I}-\mathbf{P}_1)\mathbf{X}_2]^{-}\mathbf{X}&#39;_2(\mathbf{I}-\mathbf{P}_1)\mathbf{y}=\mathbf{M}^{-}_2\mathbf{X}&#39;_2(\mathbf{I}-\mathbf{P}_1)\mathbf{y}\\
\hat\sigma^2=&amp;\frac{1}{n-r}(\mathbf{y}-\mathbf{X}_1\boldsymbol\beta^0_1-\mathbf{X}_2\boldsymbol\beta^0_2)&#39;(\mathbf{y}-\mathbf{X}_1\boldsymbol\beta^0_1-\mathbf{X}_2\boldsymbol\beta^0_2)
\end{split}
\end{equation}\]</span></p>
<div id="underfitting" class="section level3" number="9.3.1">
<h3><span class="header-section-number">9.3.1</span> Underfitting</h3>
<p>In practice, due to data limitation or other reasons, one may only use a subset of the true predictors to fit the model.
If the fitted model <span class="math inline">\(\mathbf{y}=\mathbf{X}_1\boldsymbol\beta_1 + \boldsymbol\varepsilon\)</span> doesn’t contain <span class="math inline">\(\mathbf{X}_2\)</span> and <span class="math inline">\(\boldsymbol\beta_2\)</span>, the least squares solutions are</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
\boldsymbol\beta^0_{1,H}=&amp;(\mathbf{X}&#39;_1\mathbf{X}_1)^{-}\mathbf{X}&#39;_1\mathbf{y}\\
\hat\sigma^2_{1,H}=&amp;\frac{1}{n-r_1}\mathbf{y}&#39;(\mathbf{I}-\mathbf{P}_1)\mathbf{y}
\end{split}
\end{equation}\]</span></p>
<p>It is clear that <span class="math inline">\(\boldsymbol\beta^0_{1,H}\)</span> and <span class="math inline">\(\hat\sigma^2_{1,H}\)</span> are biased estimates because</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
E[\boldsymbol\beta^0_{1,H}]=&amp;(\mathbf{X}&#39;_1\mathbf{X}_1)^{-}\mathbf{X}&#39;_1\mathbf{X}_1\boldsymbol\beta_1+(\mathbf{X}&#39;_1\mathbf{X}_1)^{-}\mathbf{X}&#39;_1\mathbf{X}_2\boldsymbol\beta_2\\
=&amp;\mathbf{H}\boldsymbol\beta_1+\mathbf{M}_1\boldsymbol\beta_2
\end{split}
\end{equation}\]</span></p>
<p>and</p>
<p><span class="math display">\[\begin{equation}
E[\hat\sigma^2_{1,H}]=\sigma^2 + \frac{1}{n-r_1}\boldsymbol\beta&#39;_2\mathbf{X}&#39;_2(\mathbf{I}-\mathbf{P}_1)\mathbf{X}_2\boldsymbol\beta_2
=\sigma^2 + \frac{1}{n-r_1}\boldsymbol\beta&#39;_2\mathbf{M}\boldsymbol\beta_2
\end{equation}\]</span></p>
<p><span class="math inline">\(E[\boldsymbol\beta^0_{1,H}]=\boldsymbol\beta_1\)</span> and <span class="math inline">\(E[\hat\sigma^2_{1,H}]=\sigma^2\)</span> only when <span class="math inline">\(\boldsymbol\beta_2=0\)</span> or <span class="math inline">\(\mathbf{M}_1=0\)</span>. The later is <span class="math inline">\(\mathbf{X}_1\perp\mathbf{X}_2\)</span> or <span class="math inline">\(\mathbf{X}&#39;_1\mathbf{X}_2=0\)</span>.</p>
<p>Since <span class="math inline">\(\mathbf{\hat Y}_{0,H}=\mathbf{X}_{0,1}\boldsymbol\beta^0_{1,H}\)</span>, <span class="math inline">\(\mathbf{\hat Y}_{0,H}\)</span> is also biased unless <span class="math inline">\(\boldsymbol\beta_2=0\)</span> or <span class="math inline">\(\mathbf{X}_1\)</span> is orthogonal to <span class="math inline">\(\mathbf{X}_2\)</span>.</p>
<p>Denote <span class="math inline">\(MSE_{H}\)</span> as the error mean squares of underfitting model. <span class="math inline">\(MSE=\text{Var-cov}[\boldsymbol{\hat\beta}]+\text{Bias}\cdot\text{Bias}&#39;\)</span>. Then</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
MSE_{H}=&amp;\sigma^2(\mathbf{X}&#39;_1\mathbf{X}_1)^{-} + \mathbf{M}_1\boldsymbol\beta_2\boldsymbol\beta_2&#39;\mathbf{M}&#39;_1\\
MSE=&amp;\sigma^2(\mathbf{X}&#39;_1\mathbf{X}_1)^{-} + \mathbf{M}_1Cov[\boldsymbol\beta_2^0]\mathbf{M}&#39;_1\\
\end{split}
\end{equation}\]</span></p>
<p>Since <span class="math inline">\(Cov[\boldsymbol\beta_2^0]-\boldsymbol\beta_2\boldsymbol\beta_2&#39;\)</span> is a positive semidefinite matrix (p.s.d.), <span class="math inline">\(MSE\ge MSE_{H}\)</span> always holds.</p>
</div>
<div id="overfitting" class="section level3" number="9.3.2">
<h3><span class="header-section-number">9.3.2</span> Overfitting</h3>
<p>In contrast, One may fit a model with extra irrelevant factors.
That is, the true model is <span class="math inline">\(\mathbf{y}=\mathbf{X}_1\boldsymbol\beta_1 + \boldsymbol\varepsilon\)</span>
and the fitted model is <span class="math inline">\(\mathbf{y}=\mathbf{X}_1\boldsymbol\beta_1 + \mathbf{X}_2\boldsymbol\beta_2 + \boldsymbol\varepsilon\)</span>.</p>
<p>This case implies <span class="math inline">\(\boldsymbol\beta_2=0\)</span>. Then all above estimates are unbiased.</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
E[\boldsymbol\beta^0_{1,H}]=&amp;\mathbf{H}\boldsymbol\beta_1+\mathbf{M}_1\boldsymbol\beta_2=\mathbf{H}\boldsymbol\beta_1\\
E[\hat\sigma^2_{1,H}]=&amp;\sigma^2 + \frac{1}{n-r_1}\boldsymbol\beta&#39;_2\mathbf{M}\boldsymbol\beta_2=\sigma^2\\
MSE_{H}=&amp;\sigma^2(\mathbf{X}&#39;_1\mathbf{X}_1)^{-} + \mathbf{M}_1\boldsymbol\beta_2\boldsymbol\beta_2&#39;\mathbf{M}&#39;_1=\sigma^2(\mathbf{X}&#39;_1\mathbf{X}_1)^{-}\\
\end{split}
\end{equation}\]</span></p>
<p>Overfitting model fits the data too closely and may only capture the random noise.
Or the extra factors are accidentally related to the response in this data.
Hence, the overfitting models produce false positive relationship and perform badly in prediction.</p>
<div style="page-break-after: always;"></div>
<!-- ## Other Topics -->
<!-- ### Bayesian approaches (Opt.) -->
<!-- ### SEM (Opt.) -->
<!-- Another attempt tries the method of structural equation modeling (SEM). The two studies capture higher elasticities of per capita VMT with respect to density (-0.38 and -0.238) [@cerveroEffectsBuiltEnvironments2010; @ewingStructuralEquationModels2014]. -->
<!-- In general, modeling is a case-by-case work. Researchers may have their preferred model by weighing the sensitivity and robustness even given the same hypothesis and data. -->
<!-- The published papers usually don't show the results of diagnosis and validation. -->
<!-- Under this circumstance, compare or summarize these outcomes are unreliable. -->

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-schwarzEstimatingDimensionModel1978" class="csl-entry">
Schwarz, Gideon. 1978. <span>“Estimating the <span>Dimension</span> of a <span>Model</span>.”</span> <em>The Annals of Statistics</em> 6 (2): 461–64. <a href="https://www.jstor.org/stable/2958889">https://www.jstor.org/stable/2958889</a>.
</div>
</div>
<div id="disqus_thread"></div>

<style>
.hide-social-discuss {
   background: white;
   height: 20px;
   position: relative;
   width: 80%;
   top: -60px;
}
</style>

<script>
    /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://qs26.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();

    //add this to script
    $("#disqus_thread").append("<div class='hide-social-discuss'></div>")

</script>



<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </section>

          </div>
        </div>
      </div>
<a href="multicollinearity.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="new-trends.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/qushen26/field_paper/edit/master/files/06-issues.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/qushen26/field_paper/blob/master/files/06-issues.Rmd",
"text": null
},
"download": ["field_paper.pdf", "field_paper.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
