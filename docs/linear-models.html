<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Linear Models | The Association Between Travel Behavior and Urban Form</title>
  <meta name="description" content="This is a field paper using the bookdown package. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.23.4 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Linear Models | The Association Between Travel Behavior and Urban Form" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a field paper using the bookdown package. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="qushen26/field_paper" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Linear Models | The Association Between Travel Behavior and Urban Form" />
  
  <meta name="twitter:description" content="This is a field paper using the bookdown package. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="Shen Qu" />


<meta name="date" content="2021-09-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="struc.html"/>
<link rel="next" href="mixed-models.html"/>
<script src="book_assets/header-attrs-2.10/header-attrs.js"></script>
<script src="book_assets/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="book_assets/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="book_assets/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="book_assets/kePrint-0.0.1/kePrint.js"></script>
<link href="book_assets/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="book_assets/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<script src="book_assets/viz-1.8.2/viz.js"></script>
<link href="book_assets/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="book_assets/grViz-binding-1.0.6.1/grViz.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Field Paper</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="part"><span><b>Part I Theories and Framework</b></span></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#background"><i class="fa fa-check"></i><b>1.1</b> Background</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#analytical-framework"><i class="fa fa-check"></i><b>1.2</b> Analytical Framework</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#content-organization"><i class="fa fa-check"></i><b>1.3</b> Content Organization</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="form.html"><a href="form.html"><i class="fa fa-check"></i><b>2</b> Urban Form as Predictors</a>
<ul>
<li class="chapter" data-level="2.1" data-path="form.html"><a href="form.html#influencing-direction"><i class="fa fa-check"></i><b>2.1</b> Influencing Direction</a></li>
<li class="chapter" data-level="2.2" data-path="form.html"><a href="form.html#influencing-factors"><i class="fa fa-check"></i><b>2.2</b> Influencing Factors</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="form.html"><a href="form.html#individual-factors"><i class="fa fa-check"></i><b>2.2.1</b> Individual Factors</a></li>
<li class="chapter" data-level="2.2.2" data-path="form.html"><a href="form.html#environmental-factors"><i class="fa fa-check"></i><b>2.2.2</b> Environmental Factors</a></li>
<li class="chapter" data-level="2.2.3" data-path="form.html"><a href="form.html#density"><i class="fa fa-check"></i><b>2.2.3</b> Density</a></li>
<li class="chapter" data-level="2.2.4" data-path="form.html"><a href="form.html#d-variables"><i class="fa fa-check"></i><b>2.2.4</b> D-variables</a></li>
<li class="chapter" data-level="2.2.5" data-path="form.html"><a href="form.html#synthesized-index"><i class="fa fa-check"></i><b>2.2.5</b> Synthesized Index</a></li>
<li class="chapter" data-level="2.2.6" data-path="form.html"><a href="form.html#meta-aanalysis"><i class="fa fa-check"></i><b>2.2.6</b> Meta-Aanalysis</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="form.html"><a href="form.html#scale"><i class="fa fa-check"></i><b>2.3</b> Spatial Scales</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="form.html"><a href="form.html#neighborhood-scale"><i class="fa fa-check"></i><b>2.3.1</b> Neighborhood Scale</a></li>
<li class="chapter" data-level="2.3.2" data-path="form.html"><a href="form.html#urbanregion-scale"><i class="fa fa-check"></i><b>2.3.2</b> Urban/Region Scale</a></li>
<li class="chapter" data-level="2.3.3" data-path="form.html"><a href="form.html#multi-scale-studies"><i class="fa fa-check"></i><b>2.3.3</b> Multi-scale Studies</a></li>
<li class="chapter" data-level="2.3.4" data-path="form.html"><a href="form.html#modifiable-areal-unit-problem-maup"><i class="fa fa-check"></i><b>2.3.4</b> Modifiable areal unit problem (MAUP)</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="form.html"><a href="form.html#summary"><i class="fa fa-check"></i><b>2.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="travel.html"><a href="travel.html"><i class="fa fa-check"></i><b>3</b> Travel as Response</a>
<ul>
<li class="chapter" data-level="3.1" data-path="travel.html"><a href="travel.html#travel-variables"><i class="fa fa-check"></i><b>3.1</b> Travel Variables</a></li>
<li class="chapter" data-level="3.2" data-path="travel.html"><a href="travel.html#traveler-choice"><i class="fa fa-check"></i><b>3.2</b> Traveler Choice</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="travel.html"><a href="travel.html#rational-choice-theory"><i class="fa fa-check"></i><b>3.2.1</b> Rational Choice Theory</a></li>
<li class="chapter" data-level="3.2.2" data-path="travel.html"><a href="travel.html#bounded-rational-behavior"><i class="fa fa-check"></i><b>3.2.2</b> Bounded Rational Behavior</a></li>
<li class="chapter" data-level="3.2.3" data-path="travel.html"><a href="travel.html#theory-of-planned-behavior"><i class="fa fa-check"></i><b>3.2.3</b> Theory of Planned Behavior</a></li>
<li class="chapter" data-level="3.2.4" data-path="travel.html"><a href="travel.html#prospect-theory"><i class="fa fa-check"></i><b>3.2.4</b> Prospect Theory</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="travel.html"><a href="travel.html#human-mobility"><i class="fa fa-check"></i><b>3.3</b> Human Mobility</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="travel.html"><a href="travel.html#trip-distribution-laws"><i class="fa fa-check"></i><b>3.3.1</b> Trip Distribution Laws</a></li>
<li class="chapter" data-level="3.3.2" data-path="travel.html"><a href="travel.html#time-geography"><i class="fa fa-check"></i><b>3.3.2</b> Time Geography</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="travel.html"><a href="travel.html#probability-distributions"><i class="fa fa-check"></i><b>3.4</b> Probability Distributions</a></li>
<li class="chapter" data-level="3.5" data-path="travel.html"><a href="travel.html#summary-opt."><i class="fa fa-check"></i><b>3.5</b> Summary (Opt.)</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="struc.html"><a href="struc.html"><i class="fa fa-check"></i><b>4</b> Model Structures</a>
<ul>
<li class="chapter" data-level="4.1" data-path="struc.html"><a href="struc.html#multistage"><i class="fa fa-check"></i><b>4.1</b> Multistage</a></li>
<li class="chapter" data-level="4.2" data-path="struc.html"><a href="struc.html#decision-tree"><i class="fa fa-check"></i><b>4.2</b> Decision Tree</a></li>
<li class="chapter" data-level="4.3" data-path="struc.html"><a href="struc.html#multi-scales"><i class="fa fa-check"></i><b>4.3</b> Multi-scales</a></li>
<li class="chapter" data-level="4.4" data-path="struc.html"><a href="struc.html#mixed-model"><i class="fa fa-check"></i><b>4.4</b> Mixed Model</a></li>
<li class="chapter" data-level="4.5" data-path="struc.html"><a href="struc.html#non-linear-models"><i class="fa fa-check"></i><b>4.5</b> Non-linear models</a></li>
</ul></li>
<li class="part"><span><b>Part II Regression Analysis</b></span></li>
<li class="chapter" data-level="5" data-path="linear-models.html"><a href="linear-models.html"><i class="fa fa-check"></i><b>5</b> Linear Models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="linear-models.html"><a href="linear-models.html#assumptions"><i class="fa fa-check"></i><b>5.1</b> Assumptions</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="linear-models.html"><a href="linear-models.html#additive-and-linearity"><i class="fa fa-check"></i><b>5.1.1</b> Additive and linearity</a></li>
<li class="chapter" data-level="5.1.2" data-path="linear-models.html"><a href="linear-models.html#independent-identically-distributed-iid"><i class="fa fa-check"></i><b>5.1.2</b> Independent Identically Distributed (IID)</a></li>
<li class="chapter" data-level="5.1.3" data-path="linear-models.html"><a href="linear-models.html#normality"><i class="fa fa-check"></i><b>5.1.3</b> Normality</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="linear-models.html"><a href="linear-models.html#estimations"><i class="fa fa-check"></i><b>5.2</b> Estimations</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="linear-models.html"><a href="linear-models.html#least-square"><i class="fa fa-check"></i><b>5.2.1</b> Least Square</a></li>
<li class="chapter" data-level="5.2.2" data-path="linear-models.html"><a href="linear-models.html#standardized-coefficients"><i class="fa fa-check"></i><b>5.2.2</b> Standardized coefficients</a></li>
<li class="chapter" data-level="5.2.3" data-path="linear-models.html"><a href="linear-models.html#elasticity"><i class="fa fa-check"></i><b>5.2.3</b> Elasticity</a></li>
<li class="chapter" data-level="5.2.4" data-path="linear-models.html"><a href="linear-models.html#combined-effects"><i class="fa fa-check"></i><b>5.2.4</b> Combined effects?</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="linear-models.html"><a href="linear-models.html#inference"><i class="fa fa-check"></i><b>5.3</b> Inference</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="linear-models.html"><a href="linear-models.html#analysis-of-variance"><i class="fa fa-check"></i><b>5.3.1</b> Analysis of Variance</a></li>
<li class="chapter" data-level="5.3.2" data-path="linear-models.html"><a href="linear-models.html#hypothesis-test"><i class="fa fa-check"></i><b>5.3.2</b> Hypothesis Test</a></li>
<li class="chapter" data-level="5.3.3" data-path="linear-models.html"><a href="linear-models.html#confidence-intervals"><i class="fa fa-check"></i><b>5.3.3</b> Confidence Intervals</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="linear-models.html"><a href="linear-models.html#adequacy"><i class="fa fa-check"></i><b>5.4</b> Adequacy</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="linear-models.html"><a href="linear-models.html#residuals-analysis"><i class="fa fa-check"></i><b>5.4.1</b> Residuals Analysis</a></li>
<li class="chapter" data-level="5.4.2" data-path="linear-models.html"><a href="linear-models.html#heteroscedasticity"><i class="fa fa-check"></i><b>5.4.2</b> Heteroscedasticity</a></li>
<li class="chapter" data-level="5.4.3" data-path="linear-models.html"><a href="linear-models.html#multicollinearity"><i class="fa fa-check"></i><b>5.4.3</b> Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="linear-models.html"><a href="linear-models.html#variables-selections"><i class="fa fa-check"></i><b>5.5</b> Variables Selections</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="linear-models.html"><a href="linear-models.html#goodness-of-fit"><i class="fa fa-check"></i><b>5.5.1</b> Goodness of fit</a></li>
<li class="chapter" data-level="5.5.2" data-path="linear-models.html"><a href="linear-models.html#mallows-c_p"><i class="fa fa-check"></i><b>5.5.2</b> Mallows <span class="math inline">\(C_p\)</span></a></li>
<li class="chapter" data-level="5.5.3" data-path="linear-models.html"><a href="linear-models.html#press"><i class="fa fa-check"></i><b>5.5.3</b> PRESS</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="linear-models.html"><a href="linear-models.html#other-topics"><i class="fa fa-check"></i><b>5.6</b> Other Topics</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="linear-models.html"><a href="linear-models.html#bayesian-approaches-opt."><i class="fa fa-check"></i><b>5.6.1</b> Bayesian approaches (Opt.)</a></li>
<li class="chapter" data-level="5.6.2" data-path="linear-models.html"><a href="linear-models.html#sem-opt."><i class="fa fa-check"></i><b>5.6.2</b> SEM (Opt.)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="mixed-models.html"><a href="mixed-models.html"><i class="fa fa-check"></i><b>6</b> Mixed Models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="mixed-models.html"><a href="mixed-models.html#fixed-and-random-effects"><i class="fa fa-check"></i><b>6.1</b> Fixed and Random Effects</a></li>
<li class="chapter" data-level="6.2" data-path="mixed-models.html"><a href="mixed-models.html#crossed-and-nested-effects"><i class="fa fa-check"></i><b>6.2</b> Crossed and Nested Effects</a></li>
<li class="chapter" data-level="6.3" data-path="mixed-models.html"><a href="mixed-models.html#unbalanced-subgroup"><i class="fa fa-check"></i><b>6.3</b> Unbalanced Subgroup</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="non-linear-models-1.html"><a href="non-linear-models-1.html"><i class="fa fa-check"></i><b>7</b> Non-Linear Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="non-linear-models-1.html"><a href="non-linear-models-1.html#transformations"><i class="fa fa-check"></i><b>7.1</b> Transformations</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="non-linear-models-1.html"><a href="non-linear-models-1.html#variance-stabilizing"><i class="fa fa-check"></i><b>7.1.1</b> Variance Stabilizing</a></li>
<li class="chapter" data-level="7.1.2" data-path="non-linear-models-1.html"><a href="non-linear-models-1.html#linearizing"><i class="fa fa-check"></i><b>7.1.2</b> Linearizing</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="non-linear-models-1.html"><a href="non-linear-models-1.html#polynomial-regression"><i class="fa fa-check"></i><b>7.2</b> Polynomial Regression</a></li>
<li class="chapter" data-level="7.3" data-path="non-linear-models-1.html"><a href="non-linear-models-1.html#nonparamteric-regression"><i class="fa fa-check"></i><b>7.3</b> Nonparamteric Regression</a></li>
<li class="chapter" data-level="7.4" data-path="non-linear-models-1.html"><a href="non-linear-models-1.html#generalized-additive-models"><i class="fa fa-check"></i><b>7.4</b> Generalized Additive Models</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>8</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#logistic-regression"><i class="fa fa-check"></i><b>8.1</b> Logistic Regression</a></li>
<li class="chapter" data-level="8.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#poisson-regression"><i class="fa fa-check"></i><b>8.2</b> Poisson Regression</a></li>
<li class="chapter" data-level="8.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#zero-inflated-and-hurdle-models"><i class="fa fa-check"></i><b>8.3</b> Zero-inflated and Hurdle Models</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="meta-analysis.html"><a href="meta-analysis.html"><i class="fa fa-check"></i><b>9</b> Meta-Analysis</a>
<ul>
<li class="chapter" data-level="9.0.1" data-path="meta-analysis.html"><a href="meta-analysis.html#overview"><i class="fa fa-check"></i><b>9.0.1</b> Overview</a></li>
<li class="chapter" data-level="9.0.2" data-path="meta-analysis.html"><a href="meta-analysis.html#advanced-methods"><i class="fa fa-check"></i><b>9.0.2</b> Advanced Methods</a></li>
<li class="chapter" data-level="9.0.3" data-path="meta-analysis.html"><a href="meta-analysis.html#summary-1"><i class="fa fa-check"></i><b>9.0.3</b> Summary</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>A</b> Data</a>
<ul>
<li class="chapter" data-level="A.1" data-path="data.html"><a href="data.html#travel-survey"><i class="fa fa-check"></i><b>A.1</b> Travel Survey</a></li>
<li class="chapter" data-level="A.2" data-path="data.html"><a href="data.html#census-data"><i class="fa fa-check"></i><b>A.2</b> Census Data</a></li>
<li class="chapter" data-level="A.3" data-path="data.html"><a href="data.html#smart-location-database"><i class="fa fa-check"></i><b>A.3</b> Smart Location Database</a></li>
<li class="chapter" data-level="A.4" data-path="data.html"><a href="data.html#new-data-sources"><i class="fa fa-check"></i><b>A.4</b> New Data Sources</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="discussion.html"><a href="discussion.html"><i class="fa fa-check"></i><b>B</b> Discussion</a>
<ul>
<li class="chapter" data-level="B.1" data-path="discussion.html"><a href="discussion.html#a-proposed-framework"><i class="fa fa-check"></i><b>B.1</b> A Proposed Framework</a></li>
<li class="chapter" data-level="B.2" data-path="discussion.html"><a href="discussion.html#policy-implications"><i class="fa fa-check"></i><b>B.2</b> Policy implications</a></li>
<li class="chapter" data-level="B.3" data-path="discussion.html"><a href="discussion.html#other-thoughts"><i class="fa fa-check"></i><b>B.3</b> Other thoughts</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The Association Between Travel Behavior and Urban Form</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linear-models" class="section level1" number="5">
<h1><span class="header-section-number">Chapter 5</span> Linear Models</h1>
<p>This Chapter will not give a complete introduction of linear regression. It only focus on some critical issues which are related with Travel-Urban Form models. This chapter only discusses the VMT-urban form models because the response are continue variables in regular linear models. The part of mode choice model is placed in Chapter of Generalized linear models.</p>
<div id="assumptions" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Assumptions</h2>
<div id="additive-and-linearity" class="section level3" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Additive and linearity</h3>
<p>For linear models, the most important assumptions are the additive and linear relationship between the response and predictors. Gravity Law discloses that travel distance has a multiplicative (inverse) relationship with the ‘masses’ of two places. If the population size can be a representative of built environment, the additive relationship will not hold. Previous studies also shows that the effect sizes of built environment with respect of travel are small and complex. There is not sufficient evidence to support or against the linear hypothesis.</p>
</div>
<div id="independent-identically-distributed-iid" class="section level3" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Independent Identically Distributed (IID)</h3>
<p>Another essential assumption is that random error are Independent Identically Distributed (IID). Random error is also called residual, which refer to the difference between observed <span class="math inline">\(\mathbf{y}\)</span> and fitted <span class="math inline">\(\mathbf{\hat y}\)</span>. <span class="math inline">\(\mathbf{\hat y}\)</span> are the linear combinations of predictors <span class="math inline">\(\mathbf{X}\)</span>. residuals represent the part can not be explained by the model.</p>
<p><span class="math display" id="eq:residual">\[\begin{equation}
\mathbf{e}=\mathbf{y}-\mathbf{\hat y}
\tag{5.1}
\end{equation}\]</span></p>
<p>The expected value, the variances, and the covariances among the random errors are the first- and second-moment of residuals. ‘Identical’ means that random errors should have zero mean and constant variance. The homogeneity of variance is also called homoscedasticity.</p>
<p><span class="math display" id="eq:identical">\[\begin{equation}
E(\varepsilon) = 0 \\
Var(\varepsilon) = \sigma^2\\
\tag{5.2}
\end{equation}\]</span></p>
<p>‘Independent’ requires the random errors are uncorrelated. That is</p>
<p><span class="math display" id="eq:indenpendent">\[\begin{equation}
Cov[\varepsilon_i,\varepsilon_j] = 0,\quad i\neq j
\tag{5.3}
\end{equation}\]</span></p>
<p>Once the conditions of IID are satisfied, the Gauss - Markov theorem <a href="linear-models.html#thm:g-m">5.1</a> proves that least-square method could give the minimum-variance unbiased estimators (MVUE) or called the best linear unbiased estimators (BLUE). These conditions are not strict and make regression method widely applicable.</p>
<div class="theorem">
<p><span id="thm:g-m" class="theorem"><strong>Theorem 5.1  (Gauss - Markov theorem) </strong></span>For the regression model <a href="intro.html#eq:lm">(1.1)</a> with the assumptions <span class="math inline">\(E(\varepsilon) = 0\)</span>, <span class="math inline">\(Var(\varepsilon) = \sigma^2\)</span>, and uncorrelated errors, the least-squares estimators are unbiased and have minimum variance when compared with all other unbiased estimators that are linear combinations of the <span class="math inline">\(y_i\)</span>. (Montgomery et al., 2021)</p>
<p>Another version is that: Under Models II - VII, if <span class="math inline">\(\lambda&#39;\beta\)</span> is estimable and <span class="math inline">\(\hat\beta\)</span> is any solution to the normal equations, then <span class="math inline">\(\lambda&#39;\hat\beta\)</span> is a linear unbiased estimator of <span class="math inline">\(\lambda&#39;\beta\)</span> and, under Model II, the variance of <span class="math inline">\(\lambda&#39;\hat\beta\)</span> is uniformly less than that of any other linear unbiased estimator of <span class="math inline">\(\lambda&#39;\beta\)</span> (IX, Theorem E13, p38)</p>
</div>
<p>Unfortunately, many of the predictors are correlated. Moreover, the observations from various cities, regions, or counties are very unlikely identical. This issue is called heteroscedasticity. Related contents are in Section of Diagonusis and Validation.</p>
</div>
<div id="normality" class="section level3" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> Normality</h3>
<p>When conducting hypothesis test and confidence intervals, the required assumption is <span class="math inline">\(\mathbf{y|x}\sim N (\mathbf{X}\boldsymbol{\beta},\sigma^2\mathbf{I})\)</span>. Maximum Likelihood Methods also requires this assumption.</p>
<p>Evidence has demonstrated that travel distance is not Normal distributed. The Zipf’s law also prove that travel distance follows a power distribution. Using logarithm transformations, the skewed distribution can be converted to an approximate normal distribution.</p>
<p>There are some quantitative methods which can examine nomalirty of the transformed distributions.</p>
</div>
</div>
<div id="estimations" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Estimations</h2>
<div id="least-square" class="section level3" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Least Square</h3>
<p>Least-Squares method can be used to estimate the coefficients <span class="math inline">\(\beta\)</span> in equation <a href="intro.html#eq:lm">(1.1)</a> The dimension of <span class="math inline">\(\mathbf{X}\)</span> is <span class="math inline">\(n\times p\)</span>, which means the data contain <span class="math inline">\(n\)</span> observations and <span class="math inline">\(p-1\)</span> predictors. The <span class="math inline">\(p\times1\)</span> vector of least-squares estimators is denoted as <span class="math inline">\(\hat\beta\)</span> and the solution to the normal equations is</p>
<p><span class="math display" id="eq:lsq-e">\[\begin{equation}
\boldsymbol{\hat\beta}=(\mathbf{X&#39;X})^{-1}\mathbf{X&#39;}\mathbf{y}
\tag{5.4}
\end{equation}\]</span></p>
<p>and</p>
<p><span class="math display" id="eq:lsq-v">\[\begin{equation}
\hat\sigma^2=\frac1{n-p}(\mathbf{y-X}\boldsymbol{\hat\beta})&#39;(\mathbf{y-X}\boldsymbol{\hat\beta})
\tag{5.5}
\end{equation}\]</span></p>
<p>Here requires <span class="math inline">\(\mathbf{X&#39;X}\)</span> are invertible, that is, the covariates are linearly independent if <span class="math inline">\(\mathbf{X}\)</span> has rank <span class="math inline">\(p\)</span> (V., Definition, p.22).</p>
<p>Given the estimated coefficients, the model can give the fitted values of response as:</p>
<p><span class="math display" id="eq:fitted-y">\[\begin{equation}
\mathbf{\hat y}=\mathbf{X}\boldsymbol{\hat\beta}=\mathbf{X}(\mathbf{X&#39;X})^{-1}\mathbf{X&#39;y}= \mathbf{Hy}
\tag{5.6}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\mathbf{H}=\mathbf{X}(\mathbf{X&#39;X})^{-1}\mathbf{X&#39;}\)</span> is hat matrix and <span class="math inline">\(\mathbf{e}=\mathbf{y}-\mathbf{\hat y}=\mathbf{y}-\mathbf{X}\boldsymbol{\hat\beta}=(\mathbf{I}-\mathbf{H})\mathbf{y}\)</span></p>
<p>When the observations are not independent or have unequal variances, the covariance matrix of error is not identity matrix. The assumption of regression model <span class="math inline">\(V[\boldsymbol{\varepsilon}]=\sigma^2\mathbf{I}\)</span> doesn’t hold. Denote <span class="math inline">\(\mathbf{V}\)</span> is a known <span class="math inline">\(n\times n\)</span> positive definite matrix and <span class="math inline">\(V[\boldsymbol{\varepsilon}]=\sigma^2\mathbf{V}\)</span>.
Then, there exists an <span class="math inline">\(n\times n\)</span> symmetric matrix <span class="math inline">\(\mathbf{K}\)</span> with rank <span class="math inline">\(n\)</span> and <span class="math inline">\(\mathbf{V}=\mathbf{KK&#39;}\)</span>. Let</p>
<p><span class="math display">\[\begin{equation}
\mathbf{z}=\mathbf{K&#39;y},\ \mathbf{B}=\mathbf{K^{-1}X}, \text{and}\ \boldsymbol{\eta}=\mathbf{K&#39;}\boldsymbol{\varepsilon}
\end{equation}\]</span></p>
<p>The linear model becomes <span class="math inline">\(\mathbf{z}=\mathbf{B}\boldsymbol{\beta}+\boldsymbol{\eta}\)</span> and <span class="math inline">\(V[\boldsymbol{\eta}]=\sigma^2\mathbf{I}\)</span>.
If the model is full rank, that is <span class="math inline">\(rank(\mathbf{X})=p\)</span> then <span class="math inline">\(\mathbf{X&#39;V^{-1}X}\)</span> is invertible
and the generalized least squares solution is</p>
<p><span class="math display" id="eq:glsq-e">\[\begin{equation}
\boldsymbol{\hat\beta}_{GLS}=(\mathbf{X&#39;V^{-1}X})^{-1}\mathbf{X&#39;V^{-1}}\mathbf{y}
\tag{5.7}
\end{equation}\]</span></p>
<p>and</p>
<p><span class="math display" id="eq:glsq-v">\[\begin{equation}
\hat\sigma^2_{GLS}=\frac1{n-p}(\mathbf{y-X}\boldsymbol{\hat\beta}_{GLS})&#39;(\mathbf{y-X}\boldsymbol{\hat\beta}_{GLS})
\tag{5.8}
\end{equation}\]</span></p>
</div>
<div id="standardized-coefficients" class="section level3" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Standardized coefficients</h3>
<p>The value of <span class="math inline">\(\hat \beta_j\)</span> means that, given all other coefficients fixed, for each change of one unit in <span class="math inline">\(x_j\)</span>, the average change in the mean of <span class="math inline">\(Y\)</span>. However, the units of predictors <span class="math inline">\(\mathbf{X}\)</span> are very different. Hence, the values of coefficients are not comparable.</p>
<p>Unit normal scaling or Unit length scaling can convert <span class="math inline">\(\hat \beta_j\)</span> to dimensionless regression coefficient, which is called standardized regression coefficients. Let</p>
<p><span class="math display" id="eq:standize">\[\begin{equation}
\begin{split}
z_{ij}=&amp;\frac{x_{ij}-\bar x_j}{\sqrt{\sum_{i=1}^{n}(x_{ij}-\bar x_j)^2}},\quad \\
y^{0}_{i}=&amp;\frac{y_{i}-\bar y}{\sqrt{\sum_{i=1}^{n}(y_{i}-\bar y)^2}}
\end{split}
\tag{5.9}
\end{equation}\]</span></p>
<p><span class="math display" id="eq:stand-coef">\[\begin{equation}
\begin{split}
\mathbf{\hat b}=&amp;(\mathbf{Z&#39;Z})^{-1}\mathbf{Z&#39;}\mathbf{y^{0}},\ \text{or}\\
\hat b_j= &amp;\hat\beta_j\sqrt{\frac{\sum_{i=1}^{n}(x_{ij}-\bar x_j)^2}{\sum_{i=1}^{n}(y_{i}-\bar y)^2}},\ j=1,2,...(p-1),\text{ and}\\
\hat\beta_0=&amp;\bar y - \sum_{j=1}^{p-1}\hat\beta_j\bar x_j
\end{split}
\tag{5.10}
\end{equation}\]</span></p>
<p>Note that <span class="math inline">\(\mathbf{Z&#39;Z}\)</span> correlations matrix.</p>
<p><span class="math display" id="eq:corr-matrix">\[\begin{equation}
\begin{split}
\mathbf{Z&#39;Z}=&amp;\begin{bmatrix} 
1 &amp; r_{12} &amp; r_{13} &amp; \dots &amp; r_{1k} \\  
r_{21} &amp; 1 &amp; r_{23} &amp; \dots &amp; r_{2k} \\  
r_{31} &amp; _{32} &amp; 1 &amp; \dots &amp; r_{3k} \\  
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\  
r_{k1} &amp; r_{k2} &amp; _{k3} &amp; \dots &amp; 1  \end{bmatrix},\quad 
\mathbf{Z&#39;}\mathbf{y^{0}}=&amp;\begin{bmatrix} 
r_{1y} \\ r_{2y} \\ r_{3y} \\ \vdots \\ r_{ky} \end{bmatrix}
\end{split}
\tag{5.11}
\end{equation}\]</span></p>
<p>where</p>
<p><span class="math display" id="eq:corr-1">\[\begin{equation}
\begin{split}
r_{ij}=&amp;\frac{\sum_{u=1}^{n}(x_{ui}-\bar x_i)(x_{uj}-\bar x_j)}{\sqrt{\sum_{u=1}^{n}(x_{ui}-\bar x_i)^2\sum_{u=1}^{n}(x_{uj}-\bar x_j)^2}}\\
r_{jy}=&amp;\frac{\sum_{u=1}^{n}(x_{uj}-\bar x_j)(y_{u}-\bar y)}{\sqrt{\sum_{u=1}^{n}(x_{uj}-\bar x_j)^2\sum_{u=1}^{n}(y_{u}-\bar y)^2}}
\end{split}
\tag{5.12}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(r_{ij}\)</span> is the simple correlation between <span class="math inline">\(x_i\)</span> and <span class="math inline">\(x_j\)</span>. <span class="math inline">\(r_{jy}\)</span> is the simple correlation between <span class="math inline">\(x_j\)</span> and <span class="math inline">\(y\)</span></p>
<p>It seems that standardized regression coefficients are comparable. However, the value of <span class="math inline">\(\hat b_j\)</span> depends on other predictors. Therefore, comparison between different models is still problematic.</p>
</div>
<div id="elasticity" class="section level3" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> Elasticity</h3>
<p>Definition: Commonly used to determine the relative importance of a variable in terms of its influence on a dependent variable. It is generally interpreted as the percent change in the dependent variable induced by a 1% change in the independent variable.<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a></p>
<p><span class="math display">\[e_i=\beta_i\frac{X_i}{Y_i}\approx\frac{\partial Y_i}{\partial X_i}\frac{X_i}{Y_i}\]</span></p>
<table>
<caption>Elasticity Estimates for Various Functional Forms</caption>
<colgroup>
<col width="20%" />
<col width="38%" />
<col width="40%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Model</th>
<th align="center">Marginal Effects</th>
<th align="center">Elasticity</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Linear</td>
<td align="center"><span class="math inline">\(\beta\)</span></td>
<td align="center"><span class="math inline">\(\beta\frac{X_i}{Y_i}\)</span></td>
</tr>
<tr class="even">
<td align="center">Log-linear</td>
<td align="center"><span class="math inline">\(\beta Y_i\)</span></td>
<td align="center"><span class="math inline">\(\beta X_i\)</span></td>
</tr>
<tr class="odd">
<td align="center">Linear-log</td>
<td align="center"><span class="math inline">\(\beta\frac{1}{X_i}\)</span></td>
<td align="center"><span class="math inline">\(\beta\frac{1}{Y_i}\)</span></td>
</tr>
<tr class="even">
<td align="center">Log-log</td>
<td align="center"><span class="math inline">\(\beta\frac{Y_i}{X_i}\)</span></td>
<td align="center"><span class="math inline">\(\beta\)</span></td>
</tr>
<tr class="odd">
<td align="center">Logit</td>
<td align="center"><span class="math inline">\(\beta p_i(1-p_i)\)</span></td>
<td align="center"><span class="math inline">\(\beta X_i(1-p_i)\)</span></td>
</tr>
<tr class="even">
<td align="center">Poisson</td>
<td align="center"><span class="math inline">\(\beta \lambda_i\)</span></td>
<td align="center"><span class="math inline">\(\beta X_i\)</span></td>
</tr>
<tr class="odd">
<td align="center">NB</td>
<td align="center"><span class="math inline">\(\beta \lambda_i\)</span></td>
<td align="center"><span class="math inline">\(\beta X_i\)</span></td>
</tr>
</tbody>
</table>
<p>It is strange that <span class="citation"><a href="#ref-ewingTravelBuiltEnvironment2010" role="doc-biblioref">Reid Ewing and Cervero</a> (<a href="#ref-ewingTravelBuiltEnvironment2010" role="doc-biblioref">2010</a>)</span> use the formula of <span class="math inline">\(\beta \bar X\left(1-\frac{\bar Y}{n}\right)\)</span> for Logit model.
In Poisson model and Negative Binomial model, <span class="math inline">\(\lambda_i=\exp[\mathbf{x}_i&#39;\boldsymbol{\beta}]\)</span> (Greene, 2018, eq.18-17,21).
For truncated Poisson model: <span class="math inline">\(\delta_i=\frac{(1-P_{i,0}-\lambda_i P_{i,0})}{(1-P_{i,0})^2}\cdot\lambda_i\beta\)</span> (Greene, 2018, eq.18-23).
Hurdle model will give separate marginal(partial) effects (Greene, 2018, example 18.20)</p>
</div>
<div id="combined-effects" class="section level3" number="5.2.4">
<h3><span class="header-section-number">5.2.4</span> Combined effects?</h3>
<p>Some studies sums up the standardized coefficients or elasticities and called the summation as combined effects. Although these values are dimensionless, this method is problematic because different model specifications and data ranges are not comparable.</p>
</div>
</div>
<div id="inference" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Inference</h2>
<div id="analysis-of-variance" class="section level3" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> Analysis of Variance</h3>
<p>Analysis of Variance (ANOVA) is the fundamental approach in regression analysis. Actually, this method analysis the variation in means rather than variances themselves (Casella &amp; Berger, 2002, Ch.11).</p>
<p>Once the linear relationship holds, the response <span class="math inline">\(\mathbf{y}\)</span> can be decomposed to</p>
<p><span class="math display" id="eq:ss">\[\begin{equation}
\begin{split}
\mathbf{y&#39;y}=&amp;\mathbf{y&#39;Hy}+\mathbf{y&#39;}(\mathbf{I}-\mathbf{H})\mathbf{y}\\
\mathbf{y&#39;y}=&amp;\boldsymbol{\hat\beta}\mathbf{X&#39;}\mathbf{y}+\mathbf{y&#39;y}-\boldsymbol{\hat\beta}\mathbf{X&#39;}\mathbf{y}\\
\mathbf{y&#39;y}-n\bar y^2=&amp;\boldsymbol{\hat\beta}\mathbf{X&#39;}\mathbf{y}-n\bar y^2+\mathbf{y&#39;y}-\boldsymbol{\hat\beta}\mathbf{X&#39;}\mathbf{y}\\
\sum(y-\bar y)^2=&amp;\sum(\hat y-\bar y)^2+\sum(y-\hat y)^2\\
SST =&amp; SSR + SSE
\end{split}
\tag{5.13}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(SST\)</span> is Sum of Squares Total, <span class="math inline">\(SSR\)</span> is Sum of Squares Regression, and <span class="math inline">\(SSE\)</span> is Sum of Square Error. <span class="math inline">\(SSE=\mathbf{e&#39;e}\)</span> represents the unknown part of model.</p>
<p>For Generalized Least Squares method, <span class="math inline">\(SST=\mathbf{y&#39;V^{-1}y}\)</span>, <span class="math inline">\(SSR= \boldsymbol{\hat\beta&#39;}\mathbf{B&#39;z}=\mathbf{y&#39;V^{-1}X(X&#39;V^{-1}X})^{-1}\mathbf{X&#39;V^{-1}}\mathbf{y}\)</span>, and <span class="math inline">\(SSE=SST-SSR\)</span></p>
</div>
<div id="hypothesis-test" class="section level3" number="5.3.2">
<h3><span class="header-section-number">5.3.2</span> Hypothesis Test</h3>
<ul>
<li>Significance of Regression</li>
</ul>
<p>Significance of regression means if the linear relationship between response and predictors is adequate. The hypotheses for testing model adequacy are</p>
<p><span class="math display" id="eq:hyp-1">\[\begin{equation}
\begin{split}
H_0:&amp;\quad \beta_0 = \beta_1 = \cdots =\beta_{p-1}=0\\
H_1:&amp;\quad \text{at least one } \beta_j \neq 0,\ j=0,1,...,(p-1)\\
\end{split}
\tag{5.14}
\end{equation}\]</span></p>
<p>By Theorem D14 (XX, p.90), if an <span class="math inline">\(n\times1\)</span>random vector <span class="math inline">\(\mathbf{y}\sim N(\boldsymbol{\mu},\mathbf{I})\)</span>, then</p>
<p><span class="math display" id="eq:chisq">\[\begin{equation}
\mathbf{y&#39;y} \sim \chi^2(n,\frac12\boldsymbol{\mu&#39;\mu})
\tag{5.15}
\end{equation}\]</span></p>
<p>Recall the assumption of <span class="math inline">\(\mathbf{y|x}\sim N (\mathbf{X}\boldsymbol{\beta},\sigma^2\mathbf{I})\)</span>.<br />
By the additive property of <span class="math inline">\(\chi^2\)</span> distribution,</p>
<p><span class="math display">\[\begin{equation}
\frac{MSE}{\sigma^2}=\frac{\mathbf{y&#39;(I-H)y}}{(n-p)\sigma^2} \sim \chi^2_{(n-p)}\\
\frac{MSR}{\sigma^2}=\frac{\mathbf{y&#39;Hy}}{(p-1)\sigma^2} \sim \chi^2_{(p-1)}\\
\end{equation}\]</span></p>
<p>Though <span class="math inline">\(\sigma^2\)</span> is usually unknown, by the relationship between <span class="math inline">\(\chi^2\)</span> and <span class="math inline">\(F\)</span> distributions,</p>
<p><span class="math display">\[\begin{equation}
F_0=\frac{MSE}{MSR} \sim F_{(p-1),(n-p),\lambda}\\
\end{equation}\]</span> where <span class="math inline">\(\lambda\)</span> is the non-centrality parameter. It allows to test the hypotheses given a significance level <span class="math inline">\(\alpha\)</span>. If test statistic <span class="math inline">\(F_0&gt;F_{\alpha,(p-1),(n-p)}\)</span>, then one can reject <span class="math inline">\(H_0\)</span>.</p>
<p>If a VMT-urban form model added many predictors but adjusted <span class="math inline">\(R^2\)</span> is still low, the association between travel distance and built environment might be spurious.</p>
<ul>
<li>Significance of Coefficients</li>
</ul>
<p>For testing a specific coefficient, the hypothesis is</p>
<p><span class="math display" id="eq:hyp-2">\[\begin{equation}
\begin{split}
H_0:&amp;\quad \beta_j =0\\
H_1:&amp;\quad \beta_j \neq 0\\
\end{split}
\tag{5.16}
\end{equation}\]</span></p>
<p><span class="math inline">\(\boldsymbol{\hat\beta}\)</span> is a linear combination of <span class="math inline">\(\mathbf{y}\)</span>. Based on the assumption of <span class="math inline">\(\mathbf{y|x}\sim N (\mathbf{X}\boldsymbol{\beta},\sigma^2\mathbf{I})\)</span>, it can be proved that <span class="math inline">\(\boldsymbol{\hat\beta}\sim N (\boldsymbol{\beta},\sigma^2(\mathbf{X&#39;X})^{-1})\)</span> and</p>
<p><span class="math display">\[\begin{equation}
t_0=\frac{\hat\beta_j}{se(\hat\beta_j)}=\frac{\hat\beta_j}{\sqrt{\hat\sigma^2C_{jj}}} \sim t_{(n-p)}\\
\end{equation}\]</span> where <span class="math inline">\(C_{jj}\)</span> is the element at the <span class="math inline">\(j\)</span> row and <span class="math inline">\(j\)</span> column of <span class="math inline">\((\mathbf{X&#39;X})^{-1}\)</span>. If <span class="math inline">\(|t_0|&lt; t_{\alpha/2,(n-p)}\)</span>, then the test failed to reject the <span class="math inline">\(H_0\)</span>, this predictor can be removed from the model. This test is called partial or marginal test because the test statistic for <span class="math inline">\(\beta_j\)</span> depends on all the predictors in the model.</p>
</div>
<div id="confidence-intervals" class="section level3" number="5.3.3">
<h3><span class="header-section-number">5.3.3</span> Confidence Intervals</h3>
<p>Above results can also construct the confidence interval for each coefficient. A <span class="math inline">\(100(1-\alpha)\)</span> confidence interval for <span class="math inline">\(\beta_j\)</span> is</p>
<p><span class="math display">\[\begin{equation}
\hat\beta_j-t_{\alpha/2,(n-p)}\sqrt{\hat\sigma^2C_{jj}}\le \beta_j \le \hat\beta_j+t_{\alpha/2,(n-p)}\sqrt{\hat\sigma^2C_{jj}}
\end{equation}\]</span></p>
</div>
</div>
<div id="adequacy" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> Adequacy</h2>
<p>Only estimation and inference can not demonstrate model’s performance.
If the primary assumptions is violated, the estimations could be biased and the model could be useless. These problems can also happen when the model is not correctly specified. It is necessary to make diagnosis and validation for fitted models.</p>
<!-- "There are different types of model specification errors in regression analysis: " -->
<!-- (1) necessary independent variable(s) is (are) missing from the model (i.e., omission error) (Greene 2012, 96--8, Section 4.3.2); -->
<!-- (2) irrelevant independent variable(s) is (are) added to the model (i.e., commission error) (Greene 2012, 98, Section 4.3.3); -->
<!-- (3) independent variables have an incorrect functional form (Ramsey 1969; Thursby and Schmidt 1977; Hausman 1978; Davidson and MacKinnon 1981); -->
<!-- (4) variables in the model are not accurately measured (i.e., measurement error) (Wooldridge 2015, 287--92, Section 9.4); and -->
<!-- (5) the model is not stand-alone but instead belongs to a system of simultaneous equations (Ramsey 1969; Hausman 1978). -->
<div id="residuals-analysis" class="section level3" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Residuals Analysis</h3>
<p>The major assumptions, both IID and normality are related to residual.
Residual diagnosis is an essential step for modeling validation.</p>
<p>There are several scaled residuals can help the diagnosis.
Since <span class="math inline">\(MSE\)</span> is the expected variance of error <span class="math inline">\(\hat\sigma^2\)</span> and <span class="math inline">\(E[\varepsilon]=0\)</span>, standardized residuals should follow a standard normal distribution.</p>
<p><span class="math display">\[d_i=\frac{e_i}{\sqrt{MSE}}=e_i\sqrt{\frac{n-p}{\sum_{i=1}^n e_i^2}},\quad i=1,2,...,n\]</span></p>
<p>Recall random error <span class="math inline">\(\mathbf{e}=\mathbf{y}-\mathbf{\hat y}=(\mathbf{I}-\mathbf{H})\mathbf{y}\)</span> and hat matrix <span class="math inline">\(\mathbf{H}=\mathbf{X}(\mathbf{X&#39;X})^{-1}\mathbf{X&#39;}\)</span>.
Let <span class="math inline">\(h_{ii}\)</span> denote the <span class="math inline">\(i^{th}\)</span> diagonal element of hat matrix.
Studentized Residuals can be expressed by
<span class="math display">\[r_i=\frac{e_i}{\sqrt{MSE(1-h_{ii})}},\quad i=1,2,...,n\]</span>
It is proved that <span class="math inline">\(0\le h_{ii}\le1\)</span>.
An observation with <span class="math inline">\(h_{ii}\)</span> closed to one will return a large value of <span class="math inline">\(r_i\)</span>. The <span class="math inline">\(x_i\)</span> who has strong influence on fitted value is called leverage point.</p>
<p>Ideally, the scaled residual have zero mean and unit variance. Hence, an observation with <span class="math inline">\(|d_i|&gt;3\)</span> or <span class="math inline">\(|r_i|&gt;3\)</span> is a potential outlier.</p>
<p>Predicted Residual Error Sum of Squares (PRESS) can also be used to detect outliers.
This method predicts the <span class="math inline">\(i^{th}\)</span> fitted response by excluding the <span class="math inline">\(i^{th}\)</span> observation and examine the influence of this point.
The corresponding error <span class="math inline">\(e_{(i)}=e_{i}/(1-h_{ii})\)</span> and <span class="math inline">\(V[e_{(i)}]=\sigma^2/(1-h_{ii})\)</span>.
Thus, if <span class="math inline">\(MSE\)</span> is a good estimate of <span class="math inline">\(\sigma^2\)</span>, PRESS residuals is equivalent to Studentized Residuals.</p>
<p><span class="math display">\[\frac{e_{(i)}}{\sqrt{V[e_{(i)}]}}=\frac{e_i/(1-h_{ii})}{\sqrt{\sigma^2/(1-h_{ii})}}=\frac{e_i}{\sqrt{\sigma^2(1-h_{ii})}}\]</span></p>
<ul>
<li>Residual Plot</li>
</ul>
<p>Residual plot shows the pattern of the residuals against fitted <span class="math inline">\(\mathbf{\hat y}\)</span>.
If the assumptions are valid, the shape of points should like a envelope and be evenly distributed around the horizontal line of <span class="math inline">\(e=0\)</span>.</p>
<p>A funnel shape in residual plot shows that the variance of error is a function of <span class="math inline">\(\hat y\)</span>. A suitable transformation to response or predictor could stabilize the variance.
A curved shape means the assumption of linearity is not valid. It implies that adding quadratic terms or higher-order terms might be suitable.</p>
<ul>
<li>Normal Probability Plot</li>
</ul>
<p>A histogram of residuals can check the normality assumption.
The highly right-skewed probability distribution of VMT log-transform of VMT is reasonable.</p>
<p>A better way is a normal quantile – quantile (QQ) plot of the residuals.
An ideal cumulative normal distribution should plot as a straight line.
Only looking at the <span class="math inline">\(R^2\)</span> and p-values cannot disclose this feature.</p>
</div>
<div id="heteroscedasticity" class="section level3" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> Heteroscedasticity</h3>
<p>When the assumption of constant variance is violated, the linear model is heteroscedastic.
Heteroscedasticity is common in urban studies. For example, the cities with different size are not identical. Small cities or rural areas might have homogeneous values of population density, while large cities’ densities are more variable.</p>
<p>Recall Generalized least square estimates <a href="linear-models.html#eq:glsq-e">(5.7)</a> and <a href="linear-models.html#eq:glsq-v">(5.8)</a>, if the residuals are independent but variances are not constant, a simple linear model becomes <span class="math inline">\(\boldsymbol{\varepsilon}\sim MVN(\mathbf{0},\sigma^2\mathbf{V})\)</span> where</p>
<p><span class="math display" id="eq:hete-matrix">\[\begin{equation}
\mathbf{V}=\begin{bmatrix} 
x_1^2 &amp; 0 &amp; \dots &amp; 0 \\  
0 &amp; x_2^2 &amp; \dots &amp; 0 \\  
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\  
0 &amp; 0 &amp; \dots &amp; x_n^2 \end{bmatrix},\quad 
\mathbf{V}^{-1}=\begin{bmatrix} 
\frac1{x_1^2} &amp; 0 &amp; \dots &amp; 0 \\  
0 &amp; \frac1{x_2^2} &amp; \dots &amp; 0 \\  
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\  
0 &amp; 0 &amp; \dots &amp; \frac1{x_n^2} \end{bmatrix}
\tag{5.17}
\end{equation}\]</span></p>
<p>Then <span class="math inline">\(\mathbf{X&#39;V^{-1}X}=n\)</span> and the generalized least squares solution is</p>
<p><span class="math display" id="eq:hete-e">\[\begin{equation}
\hat\beta_{1,WLS}=\frac1n\sum_{i=1}^{n}\frac{y_i}{x_i}
\tag{5.18}
\end{equation}\]</span></p>
<p>and</p>
<p><span class="math display" id="eq:hete-v">\[\begin{equation}
\hat\sigma^2_{WLS}=\frac1{n-1}\sum_{i=1}^{n}\frac{(y_i-\hat\beta_{1}x_i)^2}{x_i^2}
\tag{5.19}
\end{equation}\]</span></p>
<p>In heteroscedastic model, the OLS estimates of coefficients are still unbiased but no longer efficient.
But the estimates of variances are biased. The corresponding hypothesis test and confidence interval would be misleading.</p>
<p>Another special case is the model with aggregated variables, which is the cases of geographic unit.
Let <span class="math inline">\(u_j\)</span> and <span class="math inline">\(v_j\)</span> are the response and predictors of <span class="math inline">\(j^{th}\)</span> household in a neighborhood. <span class="math inline">\(n_i\)</span> is the sample size in each neighborhood. Then <span class="math inline">\(y_i=\sum_{j=1}^{n_i}u_j/n_i\)</span> and <span class="math inline">\(X_i=\sum_{j=1}^{n_i}v_j/n_i\)</span>. In this case,</p>
<p><span class="math display" id="eq:agg-matrix">\[\begin{equation}
\mathbf{V}=\mathbf{V}^{-1}=\begin{bmatrix} 
\frac1{n_1} &amp; 0 &amp; \dots &amp; 0 \\  
0 &amp; \frac1{n_2} &amp; \dots &amp; 0 \\  
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\  
0 &amp; 0 &amp; \dots &amp; \frac1{n_n} \end{bmatrix},\quad 
\begin{bmatrix} 
n_1 &amp; 0 &amp; \dots &amp; 0 \\  
0 &amp; n_2 &amp; \dots &amp; 0 \\  
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\  
0 &amp; 0 &amp; \dots &amp; n_n \end{bmatrix}
\tag{5.20}
\end{equation}\]</span></p>
<p>Then <span class="math inline">\(\mathbf{X&#39;V^{-1}X}=\sum_{i=1}^nn_ix_i^2\)</span> and the WLS estimate of <span class="math inline">\(\beta_1\)</span> is</p>
<p><span class="math display" id="eq:agg-e">\[\begin{equation}
\hat\beta_{1,WLS}=\frac1n\frac{\sum_{i=1}^{n}n_ix_iy_i}{\sum_{i=1}^{n}n_ix_i^2}
\tag{5.21}
\end{equation}\]</span></p>
<p>and</p>
<p><span class="math display" id="eq:agg-v">\[\begin{equation}
V[\hat\beta_{1,WLS}]=\frac{V[\sum_{i=1}^{n}n_ix_iy_i]}{(\sum_{i=1}^{n}n_ix_i^2)^2}=\frac{\sum_{i=1}^{n}n_i^2x_i^2\sigma^2/n_i}{(\sum_{i=1}^{n}n_ix_i^2)^2}=\frac{\sigma^2}{\sum_{i=1}^{n}n_ix_i^2}
\tag{5.22}
\end{equation}\]</span></p>
<p>There are three procedures, Bartlett’s likelihood ratio test, Goldfeld-Quandt test, or Breusch-Pagan test which can be used to examine heteroscedasticity (Ravishanker &amp; Dey, 2020, 8.1.3, pp.288-290)</p>
</div>
<div id="multicollinearity" class="section level3" number="5.4.3">
<h3><span class="header-section-number">5.4.3</span> Multicollinearity</h3>
<p>Multicollinearity or near-linear dependence refers to the models with highly correlated predictors. When data is generated from experimental design, the treatments <span class="math inline">\(X\)</span> could be fixed variables and be orthogonal. But travel-urban form model is observational studies and nothing can be controlled as in lab. It is known that there are complex correlations among the built-environment predictors themselves.</p>
<p>Although, the basic IID assumptions do not require that all predictors <span class="math inline">\(\mathbf{X}\)</span> are independent, when the predictors are near-linear dependent, the model is ill-conditioned and the least-square estimators are unstable.</p>
<p>multicollinearity can make the variances inflated and impact model precision seriously. If some of predictors are exact linear dependent, the matrix <span class="math inline">\(\mathbf{X&#39;X})^{-1}\)</span> will be non-invertible. If the predictors are near-linear dependent, the correlation matrix using unit length scaling <span class="math inline">\(\mathbf{Z&#39;Z}\)</span>will has a inverse matrix with inflated variances. That means that the diagonal elements of <span class="math inline">\((\mathbf{Z&#39;Z})^{-1}\)</span> are not all equal to one. The diagnoal elements are called <strong>Variance Inflation Factors</strong>, which can be used to examine multicollinearity. The VIF for a particular predictor is examined as below <a href="linear-models.html#eq:vif">(5.23)</a></p>
<p><span class="math display" id="eq:vif">\[\begin{equation}
VIF_j=\frac{1}{1-R_j^2}
\tag{5.23}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(R_j^2\)</span> is the coefficient of determination by regressing <span class="math inline">\(x_j\)</span> on all the remaining predictors.</p>
<p>A common approach is to drop off the predictor with greatest VIF and refit the model until all VIFs are less than 10. However, dropping off one or more predictors will lose many information which might be valuable for explaining response. Due to the complexity among predictors, dropping off the predictor with the greatest VIF is not always the best choice. Sometimes, removing a predictor with moderate VIF can make all VIFs less than 10 in the refitted model. Moreover, there is not an unique criteria for VIF value. When the relationship between predictor and response is weak, or the <span class="math inline">\(R^2\)</span> is low, the VIFs less than 10 may also affect the ability of estimation dramatically.</p>
<p>Orthogonalization before fitting the model might be helpful. Other approaches such as ridge regression or principal components regression could deal with multicollinearity better.</p>
<ul>
<li>Subset Selection</li>
</ul>
<p>Empirical or methodological considerations</p>
<ul>
<li>Shrinkage Methods</li>
</ul>
<div id="ridge-regression-and-lasso" class="section level4" number="5.4.3.1">
<h4><span class="header-section-number">5.4.3.1</span> Ridge Regression and Lasso</h4>
<ul>
<li>Dimention Reduction Methods</li>
</ul>
</div>
<div id="principal-components-regression-pcr" class="section level4" number="5.4.3.2">
<h4><span class="header-section-number">5.4.3.2</span> Principal Components Regression (PCR)</h4>
<p>Partial Least Square (PLS)</p>
<p>By dint of some synthetic variables, the disaggregated model’s <span class="math inline">\(R^2\)</span> can be over 0.5. But the risk is these techniques may describe the data themselves, and the results cannot be generalized. It is worthy of a deeper investigation.</p>
</div>
</div>
</div>
<div id="variables-selections" class="section level2" number="5.5">
<h2><span class="header-section-number">5.5</span> Variables Selections</h2>
<div id="goodness-of-fit" class="section level3" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> Goodness of fit</h3>
<p>This structure tell us how good the model can explain the data. Coefficient of Determination <span class="math inline">\(R^2\)</span> is a proportion to assess the quality of fitted model.</p>
<p><span class="math display" id="eq:rsq">\[\begin{equation}
R^2 =\frac{SSR}{SST}=1-\frac{SSE}{SST}
\tag{5.24}
\end{equation}\]</span></p>
<p>when <span class="math inline">\(R^2\)</span> is close to <span class="math inline">\(1\)</span>, the most of variation in response can be explained by the fitted model. Although <span class="math inline">\(R^2\)</span> is not the only criteria of a good model, it is often available in most published papers. Recall the discussion in Part I, the aggregated data will eliminate the difference among individuals, households, or neighborhoods. In the new variance structure, <span class="math inline">\(SSE\)</span> will be much less than disaggregated model. The <span class="math inline">\(R^2\)</span> in many disaggregate studies are around 0.3, while the <span class="math inline">\(R^2\)</span> in some aggregate studies can reach 0.8. A seriously underfitting model’s outputs could be biased and unstable.</p>
<p>A fact is that adding predictors into the model will never decrease <span class="math inline">\(R^2\)</span>. Thus the models with different number of predictors is not comparable. Adjusted <span class="math inline">\(R^2\)</span> can address this issue by introducing degree of freedom. The degree of freedom denotes the amount of information required to know.</p>
<p><span class="math display" id="eq:df">\[\begin{equation}
\begin{split}
df_T =&amp; df_R + df_E\\
n-1=&amp;(p-1)+(n-p)
\end{split}
\tag{5.25}
\end{equation}\]</span></p>
<p>Then, the mean square (MS) of each sum of squares (SS) can be calculated by <span class="math inline">\(MS=SS/df\)</span>. The mean square error <span class="math inline">\(MSE\)</span> is also called as the expected value of error variance <span class="math inline">\(\hat\sigma^2=MSE=SSE/(n-p)\)</span>. <span class="math inline">\(n-p\)</span> is the degree of freedom. Then adjusted <span class="math inline">\(R^2\)</span> is</p>
<p><span class="math display" id="eq:rsq-adj">\[\begin{equation}
R_{adj}^2 = 1-\frac{MSE}{MST} = 1-\frac{SSE/(n-p)}{SST/(n-1)}
\tag{5.26}
\end{equation}\]</span></p>
<p>Another similar method is <span class="math inline">\(R^2\)</span> for prediction based on PRESS.
Recall the PRESS statistic is the prediction error sum of square by fitting a model with <span class="math inline">\(n-1\)</span> observations.</p>
<p><span class="math display" id="eq:press">\[\begin{equation}
PRESS = \sum_{i=1}^n(y_i-\hat y_{(i)})^2= \sum_{i=1}^n\left(\frac{e_i}{1-h_{ii}}\right)^2
\tag{5.27}
\end{equation}\]</span></p>
<p>A model with smaller PRESS has a better ability of prediction. The <span class="math inline">\(R^2\)</span> for prediction is</p>
<p><span class="math display" id="eq:rsq-pred">\[\begin{equation}
R_{adj}^2 = 1-\frac{PRESS}{MST}
\tag{5.28}
\end{equation}\]</span></p>
</div>
<div id="mallows-c_p" class="section level3" number="5.5.2">
<h3><span class="header-section-number">5.5.2</span> Mallows <span class="math inline">\(C_p\)</span></h3>
</div>
<div id="press" class="section level3" number="5.5.3">
<h3><span class="header-section-number">5.5.3</span> PRESS</h3>
<ul>
<li><p>Underfitting models</p></li>
<li><p>Overfitting models</p></li>
<li><p>Interaction Effects</p></li>
<li><p>Polynomial Regression Models</p></li>
<li><p>Theoretical considerations</p></li>
</ul>
<div style="page-break-after: always;"></div>
</div>
</div>
<div id="other-topics" class="section level2" number="5.6">
<h2><span class="header-section-number">5.6</span> Other Topics</h2>
<div id="bayesian-approaches-opt." class="section level3" number="5.6.1">
<h3><span class="header-section-number">5.6.1</span> Bayesian approaches (Opt.)</h3>
</div>
<div id="sem-opt." class="section level3" number="5.6.2">
<h3><span class="header-section-number">5.6.2</span> SEM (Opt.)</h3>
<p>Another attempt tries the method of structural equation modeling (SEM). The two studies capture higher elasticities of per capita VMT with respect to density (-0.38 and -0.238) <span class="citation">(<a href="#ref-cerveroEffectsBuiltEnvironments2010" role="doc-biblioref">Cervero and Murakami 2010</a>; <a href="#ref-ewingStructuralEquationModels2014" role="doc-biblioref">Reid Ewing, Hamidi, et al. 2014</a>)</span>.</p>
<p>In general, modeling is a case-by-case work. Researchers may have their preferred model by weighing the sensitivity and robustness even given the same hypothesis and data.
The published papers usually don’t show the results of diagnosis and validation.
Under this circumstance, compare or summarize these outcomes are unreliable.</p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-cerveroEffectsBuiltEnvironments2010" class="csl-entry">
Cervero, Robert, and Jin Murakami. 2010. <span>“Effects of <span>Built</span> <span>Environments</span> on <span>Vehicle</span> <span>Miles</span> <span>Traveled</span>: <span>Evidence</span> from 370 <span>US</span> <span>Urbanized</span> <span>Areas</span>.”</span> <em>Environment and Planning A: Economy and Space</em> 42 (2): 400–418. <a href="https://doi.org/10.1068/a4236">https://doi.org/10.1068/a4236</a>.
</div>
<div id="ref-ewingTravelBuiltEnvironment2010" class="csl-entry">
———. 2010. <span>“Travel and the <span>Built</span> <span>Environment</span>.”</span> <em>Journal of the American Planning Association</em> 76 (3): 265–94. <a href="https://doi.org/10.1080/01944361003766766">https://doi.org/10.1080/01944361003766766</a>.
</div>
<div id="ref-ewingStructuralEquationModels2014" class="csl-entry">
Ewing, Reid, Shima Hamidi, Frank Gallivan, Arthur C Nelson, and James B Grace. 2014. <span>“Structural Equation Models of <span>VMT</span> Growth in <span>US</span> Urbanised Areas.”</span> <em>Urban Studies</em> 51 (14): 3079–96. <a href="https://doi.org/10.1177/0042098013516521">https://doi.org/10.1177/0042098013516521</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="16">
<li id="fn16"><p>McCarthy, P.S., Transportation Economics Theory and Practice: A Case Study Approach. Blackwell, Boston, 2001.<a href="linear-models.html#fnref16" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
<div id="disqus_thread"></div>

<style>
.hide-social-discuss {
   background: white;
   height: 20px;
   position: relative;
   width: 80%;
   top: -60px;
}
</style>

<script>
    /**
    *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
    *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */
    /*
    var disqus_config = function () {
    this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
    this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
    */
    (function() { // DON'T EDIT BELOW THIS LINE
    var d = document, s = d.createElement('script');
    s.src = 'https://qs26.disqus.com/embed.js';
    s.setAttribute('data-timestamp', +new Date());
    (d.head || d.body).appendChild(s);
    })();

    //add this to script
    $("#disqus_thread").append("<div class='hide-social-discuss'></div>")

</script>



<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </section>

          </div>
        </div>
      </div>
<a href="struc.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mixed-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/qushen26/field_paper/edit/master/files/05-linear.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/qushen26/field_paper/blob/master/files/05-linear.Rmd",
"text": null
},
"download": ["field_paper.pdf", "field_paper.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
